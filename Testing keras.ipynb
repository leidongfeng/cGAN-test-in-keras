{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Dense, LSTM, Input, Reshape, merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading input data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0.2 , 0.3, 0.4, 0.5], [0.3, 0.4, 0.5, 0.6], [0.2, 0.2, 0.3, 0.3]])\n",
    "Y = np.array([[0.3, 0.4, 0.5, 0.6], [0.4, 0.5, 0.6, 0.7], [0.3, 0.3, 0.3, 0.3]])\n",
    "noise = np.random.random((3, 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data = np.array([0.5, 0.2, 0.3, 0.5])\n",
    "new_data = np.reshape(new_data, (1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Defining the generator and the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try out different numbers of output dimensions\n",
    "def get_generative_model(hidden_neurons = 12, input_dim = 4):    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_neurons, activation='relu', input_dim = 4))\n",
    "    predicted = model.add(Dense(4, activation='sigmoid'))\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-0d6e80d73a79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmerge_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_dense\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'outputs'"
     ]
    }
   ],
   "source": [
    "first_input = Input(shape=(4, ))\n",
    "first_dense = Dense(4, )(first_input)\n",
    "\n",
    "second_input = Input(shape=(4, ))\n",
    "second_dense = Dense(4,)(second_input)\n",
    "\n",
    "merge_one = merge([first_dense, second_dense])\n",
    "model = Model(inputs=[first_input, second_input], outputs = merge_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfirst_input = Input(shape=(4,))\\nfirst_dense = Dense(1, )(first_input)\\n\\nsecond_input = Input(shape=(2, ))\\nsecond_dense = Dense(1, )(second_input)\\n\\nmerge_one = merge([first_dense, second_dense])\\n\\nthird_input = Input(shape=(1, ))\\nmerge_two = merge([merge_one, third_input])\\n\\nmodel = Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\\nmodel.compile(optimizer=ada_grad, loss='binary_crossentropy',\\n               metrics=['accuracy'])\\n\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "first_input = Input(shape=(4,))\n",
    "first_dense = Dense(1, )(first_input)\n",
    "\n",
    "second_input = Input(shape=(2, ))\n",
    "second_dense = Dense(1, )(second_input)\n",
    "\n",
    "merge_one = merge([first_dense, second_dense])\n",
    "\n",
    "third_input = Input(shape=(1, ))\n",
    "merge_two = merge([merge_one, third_input])\n",
    "\n",
    "model = Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\n",
    "model.compile(optimizer=ada_grad, loss='binary_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_discriminative_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=4, init='uniform', activation='relu'))\n",
    "    model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Running through model to get predictions from the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Merge can only be called on a list of tensors, not a single tensor. Received: (<tf.Tensor 'generator_input:0' shape=(4,) dtype=float32>, None)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-d839574f8a34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_generative_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenerated_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-120377be7c4b>\u001b[0m in \u001b[0;36mget_generative_model\u001b[0;34m(hidden_neurons, input_dim)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmerged_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'concat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/madli/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(inputs, mode, concat_axis, dot_axes, output_shape, output_mask, arguments, name)\u001b[0m\n\u001b[1;32m   1688\u001b[0m                             \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m                             name=name)\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/madli/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m             raise TypeError('Merge can only be called on a list of tensors, '\n\u001b[0;32m-> 1432\u001b[0;31m                             'not a single tensor. Received: ' + str(inputs))\n\u001b[0m\u001b[1;32m   1433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             raise RuntimeError('A Merge layer cannot be used more than once, '\n",
      "\u001b[0;31mTypeError\u001b[0m: Merge can only be called on a list of tensors, not a single tensor. Received: (<tf.Tensor 'generator_input:0' shape=(4,) dtype=float32>, None)"
     ]
    }
   ],
   "source": [
    "generator = get_generative_model()\n",
    "generator.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "generator.fit(X, Y)\n",
    "generated_values = generator.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5036608 ,  0.45059842,  0.53698927,  0.47853285],\n",
       "       [ 0.50947827,  0.43779942,  0.54178965,  0.46556687],\n",
       "       [ 0.50808102,  0.4705317 ,  0.51671654,  0.47299281]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Creating input for the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X = np.reshape(X, (3,4))\n",
    "# Y = np.reshape(Y, (3,4))\n",
    "# generated_input_to_discriminator = np.concatenate([X, generated_values], axis = 1)\n",
    "# generated_input_to_discriminator = np.reshape(generated_input_to_discriminator,(3,8))\n",
    "generated_input_to_discriminator = np.concatenate([X, generated_values], axis = 1) \n",
    "true_input_to_discriminator = np.concatenate([X, Y], axis = 1)\n",
    "\n",
    "#true_input_to_discriminator = np.reshape(true_input_to_discriminator,(3,8))\n",
    "#true_input_to_discriminator = Y\n",
    "\n",
    "Xdisc = np.concatenate((generated_input_to_discriminator, true_input_to_discriminator))\n",
    "Ydisc = [1] * len(generated_input_to_discriminator) + [0] * len(true_input_to_discriminator)\n",
    "new_data_disc = np.array([0.2,0.5,0.4, 0.2, 0.3, 0.6, 0.5, 0.3])\n",
    "#new_data_disc = np.reshape (new_data_disc, (2,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xdisc = Xdisc.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Running through model to get output from the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 0s - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s - loss: 0.6933 - acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.49895456],\n",
       "       [ 0.49895945],\n",
       "       [ 0.49895468],\n",
       "       [ 0.49912736],\n",
       "       [ 0.49891233],\n",
       "       [ 0.49938491]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = get_discriminative_model()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "discriminator.fit (Xdisc, Ydisc)\n",
    "discriminator.predict(Xdisc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Connecting the discriminator to the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combined_model(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    # Here generator's output are arrays that are 8 numbers long\n",
    "    # Discriminator takes inpt that is 16 numbers long\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator_containing_disciminator = combined_model(generator, discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALTERNATIVE \n",
    "DISCRIMINATOR THAT TAKES THE GENERATORS OUTPUT IMMEDIATELY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_generative_model(hidden_neurons = 12, input_dim=4):    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_neurons, activation='relu', input_dim = 4))\n",
    "    model.add(Dense(4, activation='sigmoid'))\n",
    "    #model.add(Reshape((4,1), input_shape=(1,4)))\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_discriminative_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=4, init='uniform', activation='relu'))\n",
    "    model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_data = np.reshape(new_data, (1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = get_generative_model()\n",
    "generated_values = generator.predict(new_data)\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real_input = np.reshape(Y, (1,4))\n",
    "Xdisc = np.concatenate((generated_values, real_input))\n",
    "Ydisc = [1] * len(generated_values) + [0] * len(real_input)\n",
    "new_data = np.array([0.6, 0.6, 0.6, 0.6])\n",
    "new_data = np.reshape(new_data, (1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.49939361]], dtype=float32)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = get_discriminative_model()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "discriminator.fit (Xdisc, Ydisc)\n",
    "discriminator.predict(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the discriminator with the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combined_model(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator_containing_disciminator = combined_model(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ydisc1 = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-358-162d170b862e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator_containing_disciminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYdisc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/madli/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/madli/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/madli/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1031\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                    \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m                                    exception_prefix='model target')\n\u001b[0m\u001b[1;32m   1034\u001b[0m         sample_weights = standardize_sample_weights(sample_weight,\n\u001b[1;32m   1035\u001b[0m                                                     self.output_names)\n",
      "\u001b[0;32m/home/madli/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "generator_containing_disciminator.fit(X, Ydisc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # 8. Setting optimizers for the generator and the discriminator\n",
    "d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "generator.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "generator_containing_disciminator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "discriminator.trainable = True\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_losses(i):\n",
    "    epoch = 0\n",
    "    print ('Epoch:', epoch+1)\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    for batchno in range(3):\n",
    "        inputdata = X\n",
    "        generated_audio = generator.predict(inputdata)\n",
    "        real_audio = Y\n",
    "        Xdisc = np.concatenate((real_audio, generated_audio))\n",
    "        Ydisc = [1] * len(real_audio) + [0] * len(generated_audio)\n",
    "        d_loss = discriminator.fit(Xdisc, Ydisc)  # later change to train on batch\n",
    "        d_losses.append(d_loss)\n",
    "        discriminator.trainable = False\n",
    "        g_loss = generator_containing_disciminator.fit(inputdata, len(real_audio))\n",
    "        #print g_loss\n",
    "    epoch =+ 1\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', 1)\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_losses(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        g_loss = generator_containing_disciminator.train_on_batch(inputdata, [1]*batch_size)\n",
    "        # take into account example data also. input audio - example of laugter - paper about images from Daniel. \n",
    "        \n",
    "        # 9.8 Calculate losses for the generator\n",
    "        g_losses.append(g_loss)\n",
    "        \n",
    "        # I thought the discriminator was set to not trainable already in step 9.7??\n",
    "        discriminator.trainable = True\n",
    "        # Print how many batches have been trained on \n",
    "        sys.stdout.write(' + batch: ' + str(index+1) + '/' + str(n_batches) + '\\r')\n",
    "        # Everything from the buffer will be written in the terminal \n",
    "        sys.stdout.flush()\n",
    "    return d_losses, g_losses\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
